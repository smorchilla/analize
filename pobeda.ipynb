{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zhiti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "from scipy import spatial\n",
    "import time\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_excel(r\"datasets/extremism.xlsx\")\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df['id'] = df1['id']\n",
    "df['text'] = df1['text']\n",
    "df['class'] = df1['class']\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Таким образом никто не внес большего вклад...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Можно с уверенностью сказать, что все полезное...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Славяне должны на нас работать. Если они нам б...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Русское государство росло, развивалось из свои...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Поставим власть под контроль народа</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>305</td>\n",
       "      <td>Социальное. Соответствующий подход предполагае...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>306</td>\n",
       "      <td>Рост продуктивности человеческой деятельности ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>307</td>\n",
       "      <td>Социальная дифференциация, в том числе по этни...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>308</td>\n",
       "      <td>Демографический рост и расширение экономическо...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>309</td>\n",
       "      <td>Соответственно, политика возникает в связи с у...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  class\n",
       "0      1      Таким образом никто не внес большего вклад...    3.0\n",
       "1      2  Можно с уверенностью сказать, что все полезное...    3.0\n",
       "2      3  Славяне должны на нас работать. Если они нам б...    3.0\n",
       "3      4  Русское государство росло, развивалось из свои...    3.0\n",
       "4      5                Поставим власть под контроль народа    3.0\n",
       "..   ...                                                ...    ...\n",
       "304  305  Социальное. Соответствующий подход предполагае...    0.0\n",
       "305  306  Рост продуктивности человеческой деятельности ...    0.0\n",
       "306  307  Социальная дифференциация, в том числе по этни...    0.0\n",
       "307  308  Демографический рост и расширение экономическо...    0.0\n",
       "308  309  Соответственно, политика возникает в связи с у...    0.0\n",
       "\n",
       "[309 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(\n",
    "    min_count=10,\n",
    "    window=10,\n",
    "    size=300,\n",
    "    negative=10,\n",
    "    alpha=0.5,\n",
    "    min_alpha=0.0007,\n",
    "    sample=6e-5,\n",
    "    sg=1,workers=4)\n",
    "\n",
    "exp_model = w2v_model.wv.load_word2vec_format(r'models/exp_model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'кошка' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-0b3c1945a6f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mexp_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'кошка'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    551\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[1;34m(self, word, use_norm)\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"word 'кошка' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "exp_model.most_similar('кошка')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = \"[0-9!#$%&'()*+,./:;<=>?@[\\]^_`{|}~—\\\"\\-]+\"\n",
    "\n",
    "def comma2space(word):\n",
    "    new_word = ''\n",
    "    try:\n",
    "        for char in word:\n",
    "            if char in patterns:\n",
    "                char = ' '\n",
    "            new_word += char\n",
    "    except TypeError:\n",
    "        pass\n",
    "    return new_word\n",
    "    \n",
    "def lemmatize(doc):\n",
    "    doc = re.sub(patterns, '', doc)\n",
    "    tokens = []\n",
    "    for token in doc.split():\n",
    "        if token:\n",
    "            \n",
    "            token = token.lower()\n",
    "            token = token.strip()\n",
    "            tokens.append(token)\n",
    "    return tokens\n",
    "\n",
    "def dropstopwords(docs):\n",
    "    stopwords = nltk.corpus.stopwords.words('russian')\n",
    "    sen =  []\n",
    "    for doc in docs:\n",
    "        if (doc not in stopwords):\n",
    "            sen.append(doc)\n",
    "    return sen\n",
    "\n",
    "def dropcomma(doc):\n",
    "    new_sen = ''\n",
    "    for char in doc:\n",
    "        if (char not in patterns):\n",
    "            new_sen += char\n",
    "    return new_sen\n",
    "\n",
    "def tokenize(docs):\n",
    "    docs = comma2space(docs)\n",
    "    docs = lemmatize(docs)\n",
    "    docs = dropstopwords(docs)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medium word-vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediumVector(sen):\n",
    "    medVec = np.zeros(300).reshape((1, 300))\n",
    "    count = 0\n",
    "    for word in sen:\n",
    "        try:\n",
    "            vec = exp_model.word_vec(word)\n",
    "            medVec += vec\n",
    "            count += 1\n",
    "        except:\n",
    "            pass\n",
    "    if count >= 0 :\n",
    "        medVec = medVec / count\n",
    "    return medVec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organise data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [таким, образом, никто, внес, большего, вклада...\n",
       "1      [уверенностью, сказать, полезное, хорошее, сов...\n",
       "2      [славяне, должны, работать, нам, нужны, могут,...\n",
       "3      [русское, государство, росло, развивалось, сво...\n",
       "4                   [поставим, власть, контроль, народа]\n",
       "                             ...                        \n",
       "304    [социальное, соответствующий, подход, предпола...\n",
       "305    [рост, продуктивности, человеческой, деятельно...\n",
       "306    [социальная, дифференциация, числе, этническом...\n",
       "307    [демографический, рост, расширение, экономичес...\n",
       "308    [соответственно, политика, возникает, связи, у...\n",
       "Name: text, Length: 309, dtype: object"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=df['text'].apply(tokenize)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>medVec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Таким образом никто не внес большего вклад...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[таким, образом, никто, внес, большего, вклада...</td>\n",
       "      <td>[[-0.08076643198728561, -0.03717906400561333, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Можно с уверенностью сказать, что все полезное...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[уверенностью, сказать, полезное, хорошее, сов...</td>\n",
       "      <td>[[nan, nan, nan, nan, nan, nan, nan, nan, nan,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Славяне должны на нас работать. Если они нам б...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[славяне, должны, работать, нам, нужны, могут,...</td>\n",
       "      <td>[[-0.04596193755666415, -0.04917717600862185, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Русское государство росло, развивалось из свои...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[русское, государство, росло, развивалось, сво...</td>\n",
       "      <td>[[-0.1227731704711914, -0.11972755752503872, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Поставим власть под контроль народа</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[поставим, власть, контроль, народа]</td>\n",
       "      <td>[[nan, nan, nan, nan, nan, nan, nan, nan, nan,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>305</td>\n",
       "      <td>Социальное. Соответствующий подход предполагае...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[социальное, соответствующий, подход, предпола...</td>\n",
       "      <td>[[-0.09335160627961159, -0.05264603905379772, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>306</td>\n",
       "      <td>Рост продуктивности человеческой деятельности ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[рост, продуктивности, человеческой, деятельно...</td>\n",
       "      <td>[[nan, nan, nan, nan, nan, nan, nan, nan, nan,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>307</td>\n",
       "      <td>Социальная дифференциация, в том числе по этни...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[социальная, дифференциация, числе, этническом...</td>\n",
       "      <td>[[nan, nan, nan, nan, nan, nan, nan, nan, nan,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>308</td>\n",
       "      <td>Демографический рост и расширение экономическо...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[демографический, рост, расширение, экономичес...</td>\n",
       "      <td>[[nan, nan, nan, nan, nan, nan, nan, nan, nan,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>309</td>\n",
       "      <td>Соответственно, политика возникает в связи с у...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[соответственно, политика, возникает, связи, у...</td>\n",
       "      <td>[[-0.09335160627961159, -0.05264603905379772, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  class  \\\n",
       "0      1      Таким образом никто не внес большего вклад...    3.0   \n",
       "1      2  Можно с уверенностью сказать, что все полезное...    3.0   \n",
       "2      3  Славяне должны на нас работать. Если они нам б...    3.0   \n",
       "3      4  Русское государство росло, развивалось из свои...    3.0   \n",
       "4      5                Поставим власть под контроль народа    3.0   \n",
       "..   ...                                                ...    ...   \n",
       "304  305  Социальное. Соответствующий подход предполагае...    0.0   \n",
       "305  306  Рост продуктивности человеческой деятельности ...    0.0   \n",
       "306  307  Социальная дифференциация, в том числе по этни...    0.0   \n",
       "307  308  Демографический рост и расширение экономическо...    0.0   \n",
       "308  309  Соответственно, политика возникает в связи с у...    0.0   \n",
       "\n",
       "                                             tokenized  \\\n",
       "0    [таким, образом, никто, внес, большего, вклада...   \n",
       "1    [уверенностью, сказать, полезное, хорошее, сов...   \n",
       "2    [славяне, должны, работать, нам, нужны, могут,...   \n",
       "3    [русское, государство, росло, развивалось, сво...   \n",
       "4                 [поставим, власть, контроль, народа]   \n",
       "..                                                 ...   \n",
       "304  [социальное, соответствующий, подход, предпола...   \n",
       "305  [рост, продуктивности, человеческой, деятельно...   \n",
       "306  [социальная, дифференциация, числе, этническом...   \n",
       "307  [демографический, рост, расширение, экономичес...   \n",
       "308  [соответственно, политика, возникает, связи, у...   \n",
       "\n",
       "                                                medVec  \n",
       "0    [[-0.08076643198728561, -0.03717906400561333, ...  \n",
       "1    [[nan, nan, nan, nan, nan, nan, nan, nan, nan,...  \n",
       "2    [[-0.04596193755666415, -0.04917717600862185, ...  \n",
       "3    [[-0.1227731704711914, -0.11972755752503872, -...  \n",
       "4    [[nan, nan, nan, nan, nan, nan, nan, nan, nan,...  \n",
       "..                                                 ...  \n",
       "304  [[-0.09335160627961159, -0.05264603905379772, ...  \n",
       "305  [[nan, nan, nan, nan, nan, nan, nan, nan, nan,...  \n",
       "306  [[nan, nan, nan, nan, nan, nan, nan, nan, nan,...  \n",
       "307  [[nan, nan, nan, nan, nan, nan, nan, nan, nan,...  \n",
       "308  [[-0.09335160627961159, -0.05264603905379772, ...  \n",
       "\n",
       "[309 rows x 5 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized']=df['text'].apply(tokenize)\n",
    "df['medVec']=df['tokenized'].apply(mediumVector)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = df['class'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Таким образом никто не внес большего вклад...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Можно с уверенностью сказать, что все полезное...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Славяне должны на нас работать. Если они нам б...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Русское государство росло, развивалось из свои...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Поставим власть под контроль народа</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>305</td>\n",
       "      <td>Социальное. Соответствующий подход предполагае...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>306</td>\n",
       "      <td>Рост продуктивности человеческой деятельности ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>307</td>\n",
       "      <td>Социальная дифференциация, в том числе по этни...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>308</td>\n",
       "      <td>Демографический рост и расширение экономическо...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>309</td>\n",
       "      <td>Соответственно, политика возникает в связи с у...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  class\n",
       "0      1      Таким образом никто не внес большего вклад...      3\n",
       "1      2  Можно с уверенностью сказать, что все полезное...      3\n",
       "2      3  Славяне должны на нас работать. Если они нам б...      3\n",
       "3      4  Русское государство росло, развивалось из свои...      3\n",
       "4      5                Поставим власть под контроль народа      3\n",
       "..   ...                                                ...    ...\n",
       "304  305  Социальное. Соответствующий подход предполагае...      0\n",
       "305  306  Рост продуктивности человеческой деятельности ...      0\n",
       "306  307  Социальная дифференциация, в том числе по этни...      0\n",
       "307  308  Демографический рост и расширение экономическо...      0\n",
       "308  309  Соответственно, политика возникает в связи с у...      0\n",
       "\n",
       "[309 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(df['text'], df['class'], test_size=0.1, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276    0\n",
       "29     3\n",
       "247    0\n",
       "258    0\n",
       "149    1\n",
       "      ..\n",
       "62     3\n",
       "240    0\n",
       "143    1\n",
       "121    1\n",
       "129    1\n",
       "Name: class, Length: 222, dtype: int32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "# pipeline позволяет объединить в один блок трансформер и модель, что упрощает написание кода и улучшает его читаемость\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# TfidfVectorizer преобразует тексты в числовые вектора, отражающие важность использования каждого слова из некоторого набора слов (количество слов набора определяет размерность вектора) в каждом тексте\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# линейный классификатор и классификатор методом ближайших соседей\n",
    "from sklearn import metrics\n",
    "# набор метрик для оценки качества модели\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# модуль поиска по сетке параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('knb_clf', KNeighborsClassifier(n_neighbors=10))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_ppl_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('sgd_clf', SGDClassifier(random_state=42))])\n",
    "knb_ppl_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('knb_clf', KNeighborsClassifier(n_neighbors=10))])\n",
    "sgd_ppl_clf.fit(X_train, y_train)\n",
    "knb_ppl_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 0 1 3 0]\n"
     ]
    }
   ],
   "source": [
    "pred = knb_ppl_clf.predict(['Русские вперед убивай нерусских', 'Сегодня хорошая погода', 'Винда', \"В чем смысл жизни\", \"Режьте ебаных чурок\", \"Хочу свалить в Татарстан\"])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        21\n",
      "           1       0.80      0.80      0.80        15\n",
      "           3       0.82      0.90      0.86        20\n",
      "\n",
      "    accuracy                           0.88        56\n",
      "   macro avg       0.87      0.87      0.87        56\n",
      "weighted avg       0.88      0.88      0.88        56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_sgd = sgd_ppl_clf.predict(X_test)\n",
    "print(metrics.classification_report(predicted_sgd, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.82      0.88        22\n",
      "           1       0.93      0.58      0.72        24\n",
      "           3       0.45      1.00      0.62        10\n",
      "\n",
      "    accuracy                           0.75        56\n",
      "   macro avg       0.78      0.80      0.74        56\n",
      "weighted avg       0.85      0.75      0.76        56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_sgd = knb_ppl_clf.predict(X_test)\n",
    "print(metrics.classification_report(predicted_sgd, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score and parameter combination:\n",
      "0.828327922077922 {'sgd_clf__class_weight': None, 'sgd_clf__loss': 'hinge', 'sgd_clf__penalty': 'elasticnet', 'tfidf__ngram_range': (1, 2), 'tfidf__strip_accents': None}\n"
     ]
    }
   ],
   "source": [
    "parameters = { \n",
    "              'sgd_clf__loss':['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "              'sgd_clf__class_weight':[None, 'balanced'],\n",
    "              'sgd_clf__penalty':[None, 'l2', 'l1', 'elasticnet'],\n",
    "              'tfidf__strip_accents':['ascii', 'unicode', None],\n",
    "               'tfidf__ngram_range':[(1,2), (2,3), (3,4)]\n",
    "              }\n",
    "model = GridSearchCV(sgd_ppl_clf, parameters, cv=4, n_jobs=-1).fit(X_train, y_train)\n",
    "print('Best score and parameter combination:')\n",
    "print(model.best_score_, model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.93        22\n",
      "           1       0.87      0.65      0.74        20\n",
      "           3       0.64      1.00      0.78        14\n",
      "\n",
      "    accuracy                           0.82        56\n",
      "   macro avg       0.83      0.84      0.82        56\n",
      "weighted avg       0.86      0.82      0.82        56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_ppl_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2))),\n",
    "    ('sgd_clf', SGDClassifier(penalty='elasticnet'))])\n",
    "sgd_ppl_clf.fit(X_train, y_train)\n",
    "predicted_sgd = sgd_ppl_clf.predict(X_test)\n",
    "print(metrics.classification_report(predicted_sgd, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2))),\n",
    "    ('forest_clf', RandomForestClassifier())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer(ngram_range=(1, 2))),\n",
       "                ('forest_clf', RandomForestClassifier())])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.predict(['Русский язык - самый могучий язык в мире', 'Слава нации, смерть врагам', 'Жизнь прекрасна', 'Белорусские власти объявили забастовку', 'Привет'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      1.00      0.59         8\n",
      "           1       0.47      0.70      0.56        10\n",
      "           3       0.95      0.55      0.70        38\n",
      "\n",
      "    accuracy                           0.64        56\n",
      "   macro avg       0.61      0.75      0.62        56\n",
      "weighted avg       0.79      0.64      0.66        56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_forest = forest.predict(X_test)\n",
    "print(metrics.classification_report(predicted_forest, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6428571428571429"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8214285714285714"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_ppl_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knb_ppl_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
